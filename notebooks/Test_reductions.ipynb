{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de0891ca-1da0-4c42-ae0a-79485ec550cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from xarray import DataArray\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import pytest\n",
    "import ipytest\n",
    "ipytest.autoconfig()\n",
    "\n",
    "import weakref\n",
    "\n",
    "import numpy as np\n",
    "import pytest\n",
    "import xarray as xr\n",
    "\n",
    "from climate_index_collection.reductions import (\n",
    "    grouped_mean_weighted,\n",
    "    monthly_mean_weighted,\n",
    "    monthly_mean_unweighted,\n",
    ")\n",
    "from climate_index_collection.indices import el_nino_southern_oscillation_34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98ecb371-4266-4f50-81ac-627b2546aca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([2, 6, 8, 2], dtype='int64')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time = pd.to_datetime([\"2020-02-13\", \"2021-06-13\", \"2021-08-13\", \"2022-02-13\"])\n",
    "time.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f2fdfed2-d138-400e-97a2-21c227af4ab1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "conflicting sizes for dimension 'time': length 3 on the data but length 4 on coordinate 'time'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [43]\u001b[0m, in \u001b[0;36m<cell line: 144>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    113\u001b[0m weighted_mean_2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\n\u001b[1;32m    114\u001b[0m       [[[\u001b[38;5;241m57.\u001b[39m,  \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m29.\u001b[39m],\n\u001b[1;32m    115\u001b[0m         [\u001b[38;5;241m57.\u001b[39m, \u001b[38;5;241m29.\u001b[39m, \u001b[38;5;241m29.\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m         [\u001b[38;5;241m57.\u001b[39m,  \u001b[38;5;241m0.\u001b[39m,  \u001b[38;5;241m0.\u001b[39m],\n\u001b[1;32m    124\u001b[0m         [ \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m57.\u001b[39m, \u001b[38;5;241m57.\u001b[39m]]])\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# # calculate the mean values\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# # get both february values and replace nan with 0, as xarray does it in the calculation\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# feb_2020 = values[0]\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;66;03m# feb_weighted_mean = numerator / denominator\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# weighted_mean = np.array((feb_weighted_mean, values[1], values[2]))\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m weighted_mean_should_2 \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_mean_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mweighted_mean_2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mgroup_unique\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_unique_2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mgroup_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgroup_name_2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m unweighted_mean_should_2 \u001b[38;5;241m=\u001b[39m create_mean_array(mean \u001b[38;5;241m=\u001b[39m unweighted_mean_2,\n\u001b[1;32m    148\u001b[0m                                         group_unique\u001b[38;5;241m=\u001b[39mgroup_unique_2,\n\u001b[1;32m    149\u001b[0m                                         group_name \u001b[38;5;241m=\u001b[39m group_name_2)\n\u001b[1;32m    151\u001b[0m data_2, weights_2, group_name_2, group_unique_2 \u001b[38;5;241m=\u001b[39m create_test_dataset(\n\u001b[1;32m    152\u001b[0m                                     lat \u001b[38;5;241m=\u001b[39m lat,\n\u001b[1;32m    153\u001b[0m                                     lon \u001b[38;5;241m=\u001b[39m lon,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    156\u001b[0m                                     group \u001b[38;5;241m=\u001b[39m time,\n\u001b[1;32m    157\u001b[0m                                     group_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[0;32mIn [43]\u001b[0m, in \u001b[0;36mcreate_mean_array\u001b[0;34m(mean, group_unique, group_name)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_mean_array\u001b[39m(mean, group_unique, group_name) :    \n\u001b[0;32m---> 36\u001b[0m     weights \u001b[38;5;241m=\u001b[39m \u001b[43mDataArray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlon\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mcoords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mgroup_name\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_unique\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlon\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlon\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m weights\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/core/dataarray.py:402\u001b[0m, in \u001b[0;36mDataArray.__init__\u001b[0;34m(self, data, coords, dims, name, attrs, indexes, fastpath)\u001b[0m\n\u001b[1;32m    400\u001b[0m data \u001b[38;5;241m=\u001b[39m _check_data_shape(data, coords, dims)\n\u001b[1;32m    401\u001b[0m data \u001b[38;5;241m=\u001b[39m as_compatible_data(data)\n\u001b[0;32m--> 402\u001b[0m coords, dims \u001b[38;5;241m=\u001b[39m \u001b[43m_infer_coords_and_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    403\u001b[0m variable \u001b[38;5;241m=\u001b[39m Variable(dims, data, attrs, fastpath\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    404\u001b[0m indexes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    405\u001b[0m     _extract_indexes_from_coords(coords)\n\u001b[1;32m    406\u001b[0m )  \u001b[38;5;66;03m# needed for to_dataset\u001b[39;00m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/core/dataarray.py:152\u001b[0m, in \u001b[0;36m_infer_coords_and_dims\u001b[0;34m(shape, coords, dims)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m d, s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(v\u001b[38;5;241m.\u001b[39mdims, v\u001b[38;5;241m.\u001b[39mshape):\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m s \u001b[38;5;241m!=\u001b[39m sizes[d]:\n\u001b[0;32m--> 152\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    153\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconflicting sizes for dimension \u001b[39m\u001b[38;5;132;01m{\u001b[39;00md\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    154\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msizes[d]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m on the data but length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m on \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    155\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoordinate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m         )\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m sizes \u001b[38;5;129;01mand\u001b[39;00m v\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m (sizes[k],):\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoordinate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m is a DataArray dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mit has shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m rather than expected shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msizes[k]\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatching the dimension size\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: conflicting sizes for dimension 'time': length 3 on the data but length 4 on coordinate 'time'"
     ]
    }
   ],
   "source": [
    "# ========\n",
    "# CREATE TEST DATA 0\n",
    "# ========\n",
    "\n",
    "lon = np.array([120,140,150])\n",
    "lat = np.array([-10, -5, 0])\n",
    "\n",
    "def create_data_array(values,  group, group_name) :\n",
    "    \"\"\"\n",
    "    This function creates test DataArrays from given lat, lon, group and groupname and weights.\n",
    "    -----\n",
    "    Parameters:\n",
    "        lat: numpy.adarray, list\n",
    "        lon: numpy.adarray, list\n",
    "        values: numpy.adarray\n",
    "        group: numpy.adarray, list\n",
    "        groupname: str\n",
    "    \"\"\"\n",
    "    # create dummy dataset \n",
    "    data = DataArray(values, \n",
    "                     dims=(group_name, \n",
    "                           \"lat\", \n",
    "                           \"lon\"), \n",
    "                     coords={group_name : group, \n",
    "                             \"lat\": lat, \n",
    "                             'lon': lon})\n",
    "    return data\n",
    "\n",
    "def create_weight_array(wei, group, group_name) :    \n",
    "    weights = DataArray(wei, \n",
    "                        dims=(group_name), \n",
    "                        coords={group_name : group})\n",
    "    return weights \n",
    "\n",
    "def create_mean_array(mean, group_unique, group_name) :    \n",
    "    weights = DataArray(mean, \n",
    "                 dims=(group_name, \"lat\", \"lon\"), \n",
    "                 coords={group_name : group_unique, \"lat\": lat, 'lon': lon})\n",
    "    return weights \n",
    "# ----------\n",
    "# First test DataArray\n",
    "weights = [1, 2, 3, 2]\n",
    "group = ['a','b','a','c']\n",
    "group_name_1 = \"group\" \n",
    "group_unique_1 = np.unique(group)\n",
    "\n",
    "np.random.seed(100)\n",
    "values = np.random.randint(0,2, (len(group), len(lat), len(lon)) ).astype(float)\n",
    "values[0,0,0] = np.nan\n",
    "data_1 = create_data_array(values = values, \n",
    "                            group = group,\n",
    "                            group_name = group_name_1)\n",
    "weights_1 = create_weight_array(wei = weights,\n",
    "                                group = group,\n",
    "                                group_name = group_name_1)\n",
    "\n",
    "\n",
    "# Should be the correct values\n",
    "weighted_mean_1 = np.array(\n",
    "      [[[0.  , 0.75, 0.25],\n",
    "        [1.  , 0.25, 0.25],\n",
    "        [0.  , 0.75, 0.75]],\n",
    "\n",
    "       [[0.  , 0.  , 1.  ],\n",
    "        [0.  , 0.  , 0.  ],\n",
    "        [0.  , 1.  , 0.  ]],\n",
    "\n",
    "       [[1.  , 0.  , 0.  ],\n",
    "        [1.  , 0.  , 0.  ],\n",
    "        [1.  , 1.  , 1.  ]]])\n",
    "\n",
    "weighted_mean_should_1 = create_mean_array(mean = weighted_mean,\n",
    "                                        group_unique=group_unique_1,\n",
    "                                        group_name = group_name_1)\n",
    "# ----------\n",
    "# Second test DataArray\n",
    "time = pd.to_datetime([\"2020-02-13\", \"2021-06-13\", \"2021-08-13\", \"2022-02-13\"])\n",
    "group_2 = time.days_in_month\n",
    "group_unique_2 = np.unique(time.month)\n",
    "group_name = \"month\"\n",
    "# create values Note that we will use the \n",
    "#np.random.seed(100)\n",
    "#values = np.random.randint(0,2, (len(group), len(lat), len(lon)) ).astype(float) * (29+28)\n",
    "#values[0,0,0] = np.nan\n",
    "values_2 = np.array(\n",
    "      [[[np.nan,  0., 57.],\n",
    "        [57., 57., 57.],\n",
    "        [ 0.,  0.,  0.]],\n",
    "\n",
    "       [[ 0.,  0., 57.],\n",
    "        [ 0.,  0.,  0.],\n",
    "        [ 0., 57.,  0.]],\n",
    "\n",
    "       [[ 0., 57.,  0.],\n",
    "        [57.,  0.,  0.],\n",
    "        [ 0., 57., 57.]],\n",
    "\n",
    "       [[57.,  0.,  0.],\n",
    "        [57.,  0.,  0.],\n",
    "        [57., 57., 57.]]])\n",
    "unweighted_mean_2 = np.array(\n",
    "      [[[57,  0., 28.5,],\n",
    "        [57, 28.5, 28.5,],\n",
    "        [28.5, 28.5, 28.5]],\n",
    "\n",
    "       [[ 0.,  0., 57.],\n",
    "        [ 0.,  0.,  0.],\n",
    "        [ 0., 57.,  0.]],\n",
    "\n",
    "       [[ 0., 57.,  0.],\n",
    "        [57.,  0.,  0.],\n",
    "        [ 0., 57., 57.]]])\n",
    "\n",
    "weighted_mean_2 = np.array(\n",
    "      [[[57.,  0., 29.],\n",
    "        [57., 29., 29.],\n",
    "        [28., 28., 28.]],\n",
    "\n",
    "       [[ 0.,  0., 57.],\n",
    "        [ 0.,  0.,  0.],\n",
    "        [ 0., 57.,  0.]],\n",
    "\n",
    "       [[ 0., 57.,  0.],\n",
    "        [57.,  0.,  0.],\n",
    "        [ 0., 57., 57.]]])\n",
    "# # calculate the mean values\n",
    "# # get both february values and replace nan with 0, as xarray does it in the calculation\n",
    "# feb_2020 = values[0]\n",
    "# #feb_2020[np.isnan(feb_2020)] = 0\n",
    "# feb_2020_len = 29\n",
    "# feb_2022 = values[3]\n",
    "# #feb_2022[np.isnan(feb_2022)] = 0\n",
    "# feb_2022_len = 28\n",
    "# # for the mean calcultion we need to take care of nans.\n",
    "# # Those will not be acconuted for at all!\n",
    "# numerator = np.nansum(np.dstack(\n",
    "#                         (feb_2020 * feb_2020_len , feb_2022 * feb_2022_len))\n",
    "#                       , 2)\n",
    "# denominator_2020 = (~np.isnan(feb_2020)).astype(int) * feb_2020_len\n",
    "# denominator_2022 = (~np.isnan(feb_2022)).astype(int) * feb_2022_len\n",
    "# denominator = denominator_2020 + denominator_2022\n",
    "# feb_weighted_mean = numerator / denominator\n",
    "# weighted_mean = np.array((feb_weighted_mean, values[1], values[2]))\n",
    "\n",
    "weighted_mean_should_2 = create_mean_array(mean = weighted_mean_2,\n",
    "                                        group_unique=group_unique_2,\n",
    "                                        group_name = group_name_2)\n",
    "unweighted_mean_should_2 = create_mean_array(mean = unweighted_mean_2,\n",
    "                                        group_unique=group_unique_2,\n",
    "                                        group_name = group_name_2)\n",
    "\n",
    "data_2, weights_2, group_name_2, group_unique_2 = create_test_dataset(\n",
    "                                    lat = lat,\n",
    "                                    lon = lon,\n",
    "                                    values = values_2, \n",
    "                                    wei = weight_time,\n",
    "                                    group = time,\n",
    "                                    group_name = \"time\")\n",
    "# aslo create a dataset\n",
    "dataset_2 = data_2.to_dataset(dim=None, name=\"test\", promote_attrs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1f029959-8d62-4190-ad6d-01251e7c01f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.parametrize(\"data, weights, dim     , groupby_dim, weighted_mean_should\",[ \n",
    "    (data_1, weights_1, group_name_1 , group_name_1 , group_mean_should_1),\n",
    "    (data_2, weights_2, \"time\" , \"time.month\" , group_mean_should_2),\n",
    "                         ])\n",
    "def test_grouped_mean_weighted(data, weights, dim, groupby_dim, weighted_mean_should):\n",
    "    \"\"\"Checks if the groupby weighting function gives proper results.\"\"\"\n",
    "    result = grouped_mean_weighted(dobj=data, weights= weights, dim = dim, groupby_dim= groupby_dim)\n",
    "    assert result.equals(weighted_mean_should)\n",
    "\n",
    "@pytest.mark.parametrize(\"data_set, name, weighted_mean_should\",[ \n",
    "        (dataset_2, \"test\", weighted_mean_2),\n",
    "])\n",
    "def test_monthly_mean_unweighted(data_set, name, weighted_mean_should):\n",
    "    \"\"\"Checks if the monthly mean weighted function gives proper results.\"\"\"\n",
    "    result = monthly_mean_weighted(dobj=data_set)\n",
    "    print(result)\n",
    "    print(weighted_mean_2)\n",
    "    assert result[name].equals(weighted_mean_should)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5c026cb0-823c-443c-996c-cbd3acb0b774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
      "platform linux -- Python 3.9.12, pytest-7.1.2, pluggy-1.0.0\n",
      "rootdir: /work, configfile: pyproject.toml\n",
      "plugins: anyio-3.5.0\n",
      "collected 3 items\n",
      "\n",
      "tmpouoiqvwr.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31mF\u001b[0m\u001b[31m                                                                           [100%]\u001b[0m\n",
      "\n",
      "============================================= FAILURES =============================================\n",
      "\u001b[31m\u001b[1m________________ test_monthly_mean_unweighted[data_set0-test-weighted_mean_should0] ________________\u001b[0m\n",
      "\n",
      "data_set = <xarray.Dataset>\n",
      "Dimensions:  (time: 4, lat: 3, lon: 3)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 2020-02-13 202... (lon) int64 120 140 150\n",
      "Data variables:\n",
      "    test     (time, lat, lon) float64 nan 0.0 57.0 57.0 ... 0.0 57.0 57.0 57.0\n",
      "name = 'test'\n",
      "weighted_mean_should = array([[[57.,  0., 29.],\n",
      "        [57., 29., 29.],\n",
      "        [28., 28., 28.]],\n",
      "\n",
      "       [[ 0.,  0., 57.],\n",
      "        [ 0.,  0.,  0.],\n",
      "        [ 0., 57.,  0.]],\n",
      "\n",
      "       [[ 0., 57.,  0.],\n",
      "        [57.,  0.,  0.],\n",
      "        [ 0., 57., 57.]]])\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdata_set, name, weighted_mean_should\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,[\n",
      "            (dataset_2, \u001b[33m\"\u001b[39;49;00m\u001b[33mtest\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, weighted_mean_2),\n",
      "    ])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_monthly_mean_unweighted\u001b[39;49;00m(data_set, name, weighted_mean_should):\n",
      "        \u001b[33m\"\"\"Checks if the monthly mean weighted function gives proper results.\"\"\"\u001b[39;49;00m\n",
      "        result = monthly_mean_weighted(dobj=data_set)\n",
      "        \u001b[96mprint\u001b[39;49;00m(result)\n",
      "        \u001b[96mprint\u001b[39;49;00m(weighted_mean_2)\n",
      ">       \u001b[94massert\u001b[39;49;00m result[name].equals(weighted_mean_should)\n",
      "\u001b[1m\u001b[31mE       AssertionError: assert False\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  where False = <bound method DataArray.equals of <xarray.DataArray 'test' (month: 3, lat: 3, lon: 3)>\\narray([[[57.,  0., 29.],\\n      ...)\\nCoordinates:\\n  * lat      (lat) int64 -10 -5 0\\n  * lon      (lon) int64 120 140 150\\n  * month    (month) int64 2 6 8>(array([[[57.,  0., 29.],\\n        [57., 29., 29.],\\n        [28., 28., 28.]],\\n\\n       [[ 0.,  0., 57.],\\n        [ 0.,  0.,  0.],\\n        [ 0., 57.,  0.]],\\n\\n       [[ 0., 57.,  0.],\\n        [57.,  0.,  0.],\\n        [ 0., 57., 57.]]]))\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +    where <bound method DataArray.equals of <xarray.DataArray 'test' (month: 3, lat: 3, lon: 3)>\\narray([[[57.,  0., 29.],\\n      ...)\\nCoordinates:\\n  * lat      (lat) int64 -10 -5 0\\n  * lon      (lon) int64 120 140 150\\n  * month    (month) int64 2 6 8> = <xarray.DataArray 'test' (month: 3, lat: 3, lon: 3)>\\narray([[[57.,  0., 29.],\\n        [57., 29., 29.],\\n        [28., 2...])\\nCoordinates:\\n  * lat      (lat) int64 -10 -5 0\\n  * lon      (lon) int64 120 140 150\\n  * month    (month) int64 2 6 8.equals\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m/tmp/ipykernel_609/1503960268.py\u001b[0m:18: AssertionError\n",
      "--------------------------------------- Captured stdout call ---------------------------------------\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 3, lon: 3, month: 3)\n",
      "Coordinates:\n",
      "  * lat      (lat) int64 -10 -5 0\n",
      "  * lon      (lon) int64 120 140 150\n",
      "  * month    (month) int64 2 6 8\n",
      "Data variables:\n",
      "    test     (month, lat, lon) float64 57.0 0.0 29.0 57.0 ... 0.0 0.0 57.0 57.0\n",
      "[[[57.  0. 29.]\n",
      "  [57. 29. 29.]\n",
      "  [28. 28. 28.]]\n",
      "\n",
      " [[ 0.  0. 57.]\n",
      "  [ 0.  0.  0.]\n",
      "  [ 0. 57.  0.]]\n",
      "\n",
      " [[ 0. 57.  0.]\n",
      "  [57.  0.  0.]\n",
      "  [ 0. 57. 57.]]]\n",
      "===================================== short test summary info ======================================\n",
      "FAILED tmpouoiqvwr.py::test_monthly_mean_unweighted[data_set0-test-weighted_mean_should0] - Asser...\n",
      "\u001b[31m=================================== \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m2 passed\u001b[0m\u001b[31m in 0.28s\u001b[0m\u001b[31m ====================================\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.TESTS_FAILED: 1>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipytest.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "837f72b0-04a6-4764-953f-f55104ea8e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result <xarray.DataArray 'test' (month: 3, lat: 3, lon: 3)>\n",
      "array([[[57.,  0., 29.],\n",
      "        [57., 29., 29.],\n",
      "        [28., 28., 28.]],\n",
      "\n",
      "       [[ 0.,  0., 57.],\n",
      "        [ 0.,  0.,  0.],\n",
      "        [ 0., 57.,  0.]],\n",
      "\n",
      "       [[ 0., 57.,  0.],\n",
      "        [57.,  0.,  0.],\n",
      "        [ 0., 57., 57.]]])\n",
      "Coordinates:\n",
      "  * lat      (lat) int64 -10 -5 0\n",
      "  * lon      (lon) int64 120 140 150\n",
      "  * month    (month) int64 2 6 8\n",
      "wM [[[57.  0. 29.]\n",
      "  [57. 29. 29.]\n",
      "  [28. 28. 28.]]\n",
      "\n",
      " [[ 0.  0. 57.]\n",
      "  [ 0.  0.  0.]\n",
      "  [ 0. 57.  0.]]\n",
      "\n",
      " [[ 0. 57.  0.]\n",
      "  [57.  0.  0.]\n",
      "  [ 0. 57. 57.]]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def test_monthly_mean_weighted(data_set, name, weighted_mean_should):\n",
    "    \"\"\"Checks if the monthly mean weighted function gives proper results.\"\"\"\n",
    "    result = monthly_mean_weighted(dobj=data_set)\n",
    "    print(\"result\", result[\"test\"])\n",
    "    print(\"wM\", weighted_mean_2)\n",
    "    \n",
    "test_monthly_mean_weighted(dataset_2, \"test\", weighted_mean_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "347a11e9-adb5-4d51-907a-88eb066cec90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mmonthly_mean_weighted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Calculates the weighted monthly mean values of a dataset.\n",
       "It will make use of the grouped_mean_weighted function, which is similar to the mean_weigthed function, \n",
       "but additionally allow to include a dimension to group the data by.\n",
       "It takes care of leap years and thus differs from \"monthly_mean_unweighted\"\n",
       "Adapted from: https://docs.xarray.dev/en/stable/examples/monthly-means.html\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "dobj: xarray.Dataset or xarray.DataArray\n",
       "    Contains the original data.\n",
       "Returns\n",
       "-------\n",
       "xarray.Dataset or xarray.DataArray\n",
       "    Monthly mean data. Has the same variable name(s) as dobj. \n",
       "    Dimension 'time' will be removed.\n",
       "    Dimension 'month' is gained. \n",
       "        Int values, starting with 1 for January and ending with 12 for December.\n",
       "\u001b[0;31mFile:\u001b[0m      /work/climate_index_collection/reductions.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "monthly_mean_weighted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ab59dc1-0b1f-4620-86b6-802c47258e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.equals(group_mean_should_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de469660-c5fb-4b8e-92da-3fc521679854",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
